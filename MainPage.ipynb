{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Product Review  Sentiment analysis and Reccomender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract:\n",
    "\n",
    "Every day thousands of people leave their opinion online. They are being posted, tweeted, shared, left on online retailers’ own sites and on platforms like Amazon and TripAdvisor. Consumers are leaving their opinions about products they are considering, items they have bought or services they are using. For this project, we have performed sentiment analysis and even built a product recommender system on the dataset of amazon reviews for their jewellery items. Sentiment analysis allows retailers and brands alike to understand the opinions of consumer feedback and User Generated Content. Then, we have also built a product recommender system that can suggest the users similar kind of products. According to Amazon, it was able to increase its sales by 30% in 2015 by building a solid recommender system. Below lines give a little more detailed explaination as to what has been done in the project :\n",
    "\n",
    "This project is divided into two parts.\n",
    "\n",
    "1) Sentiment Analysis - We have done sentiment analysis of the users using two algorithms. The two algorithms that we have used are logistic regression and Naive Bayes. We have compared the results of the two to check which algorithm gives us a better result. Then, We have also analyzed the user's behaviour based on the number of ratings the user has given and what is the mean of his ratings.\n",
    "\n",
    "2) Recommender System - In this project, we have used item based Collaborative filtering approach. To implement an item based collaborative filtering, KNN is a perfect go-to model and also a very good baseline for recommender system development. KNN is a non-parametric, lazy learning method. It uses a database in which the data points are separated into several clusters to make inference for new samples.KNN does not make any assumptions on the underlying data distribution but it relies on item feature similarity. When KNN makes inference about a product, KNN will calculate the “distance” between the target product and every other product in its database, then it ranks its distances and returns the top K nearest neighbor product as the most similar product recommendations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01. [- Sentiment Analysis](./sentimentanalysis.ipynb) \n",
    "\n",
    "\n",
    "\n",
    " 02. [- Recommender System](./RecommenderSystem.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Questions:\n",
    "\n",
    "##### Did I explain my idea Correctly ?\n",
    "**Answer-** \n",
    "Yes, all our ideas have been explained clearly in the above kernels with detailed explaination of our ideas. For eg, the explaination for our approach for performing sentiment analysis using logistic regression was given as below in our notebook -\n",
    "\n",
    "\"\n",
    "1. Performing the sentiment analysis using the following techniques: Logistic regression, Logistic regression with TFIDF vectorizer and Logistic regression with TFIDF vectorizer and n-grams techniques \n",
    "<br>\n",
    "<br>\n",
    "2. Analysing the accuracy of the models and determining the best approach\n",
    "<br>\n",
    "<br>\n",
    "3. Identifying the highest-used words in each set of reviews, when grouped by rating\n",
    "<br>\n",
    "4. Applying the Navies bayes to get predict the positive or negative sentiment of Text review. \"\n",
    "\n",
    "\n",
    "##### Citations ?\n",
    "**Answer-** \n",
    "We have mentioned the citation in this kernel in the section below.\n",
    "\n",
    "##### Can NEUCOE students run your code ?\n",
    "**Answer-** \n",
    "Yes, we have not specified the local system path while importing the dataset. Moreover, the codes are easy to understand and have proper explainations which will make it easier for the students to run our code.\n",
    "\n",
    "##### Did I explain my evaluation Correctly ?\n",
    "**Answer-** \n",
    "Yes, We have explained the evaluation clearly and even done a comparison of our evaluations with different algorithms. For eg, we have explained why logistic regression was the best performing algorithm of the two.\n",
    "\n",
    "##### Did I explain my code Correctly ?\n",
    "**Answer-**\n",
    "Yes, with each code, we have given explainations as to what the code does which will make it easier for the reader to understand the codes.\n",
    "\n",
    "##### Did I explain my licensing Correctly ?\n",
    "**Answer-** \n",
    "Yes, the license of our notebooks can be found below in this kernel.\n",
    "\n",
    "##### Did I explain my conclusion Correctly ?\n",
    "**Answer-** \n",
    "Yes, we have given detailed conclusion for both our topics in the two kernels. For eg, for sentiment analysis our conclusion was as follows :\n",
    "\n",
    "\"By applying logistic regression on text review and overall review and using count vectorizer to tokenize the reviews, we were able to generate a test train model and get top 20 positive and negative words from the reviews. We got the baseline accuracy of 0.78. After applying TF-IDF vectorizer to logistic regression, we were able to improve the accuracy to 0.92. We have also implemented n-grams + TFIDF which gave us a similar accuracy of 0.92.\n",
    "\n",
    "The second algorithm that we tried was naïve bayes. The Naive Bayes algorithm is an intuitive method that uses the probabilities of each attribute belonging to each class to make a prediction. We used Multinomial and bernouli’s theorems to generate model for positive and negative sentiments and also predicted weather the review is positive or negative.\n",
    "\n",
    "We have also studied user’s behavior by taking a random user and the mean of his ratings. The user that we randomly chose appears to be really happy with the products and is biased towards giving good reviews.\n",
    "\n",
    "Results for logistic regression were better of the two algorithms that we used as the models were more accurate.\n",
    "\n",
    "Below is the comparison for all the scores that we obtained by implemeting different algorithms.\n",
    "\n",
    "Logistic Regression -\n",
    "\n",
    "Model Accuracy: 0.7825662672476398\n",
    "\n",
    "Logistic Regression with TFIDF -\n",
    "\n",
    "Model Accuracy: 0.9281726579520697\n",
    "\n",
    "Logistic Regression with TFIDF + ngrams -\n",
    "\n",
    "Model Accuracy: 0.9222267610748003\n",
    "\n",
    "Multinomial Naive Bayes -\n",
    "\n",
    "Model Accuracy: 0.7760257928011889\n",
    "\n",
    "Bernoulli's Naive Bayes -\n",
    "\n",
    "0.7739855419258961\n",
    "\n",
    "By the above data, we can say that logistic regression with TFIDF performs the best on our dataset.\"\n",
    "\n",
    "##### Did I support my conclusion with data?\n",
    "**Answer-**\n",
    "As we can see from the above conclusion, we have given data to support our conclusions.\n",
    "\n",
    "#### Is the scope enough for a semesters work? Is the scope is appropriate for the number of people in the group and it being a semester project?\n",
    "**Answer-**\n",
    "Yes, We were able to implement a bunch of stuff that we have learnt throughout the semester. We used concepts like feature engineering, logistic regression, naive bayes, sentiment analysis, k nearest neighbor, etc. This project is done by 2 people. We have not just done sentiment analysis by using different algorithms to compare their performance against each other, but we have also built a product recommender using Knn algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations:\n",
    "http://snap.stanford.edu/data/web-Amazon.html\n",
    "\n",
    "https://www.kaggle.com/linkma/starter-amazon-reviews-for-sentiment-b9ebb399-9\n",
    "\n",
    "https://www.kaggle.com/vijayabhaskar96/fully-convolutional-accuracy-94-1-15-mi-789a46\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/wordcloud-python\n",
    "\n",
    "http://www.albertauyeung.com/post/generating-ngrams-python/\n",
    "\n",
    "https://codereview.stackexchange.com/questions/124245/splitting-text-into-n-grams-and-analyzing-statistics-on-them\n",
    "\n",
    "https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
    "\n",
    "https://stackoverflow.com/questions/13423919/computing-n-grams-using-python\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/\n",
    "\n",
    "https://towardsdatascience.com/all-about-naive-bayes-8e13cef044cf\n",
    "\n",
    "https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution\n",
    "By Us- 85% <br>\n",
    "By refrences- 15%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "Copyright 2019 JAYESH V PATIL and KUNAL JAISWAL\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
